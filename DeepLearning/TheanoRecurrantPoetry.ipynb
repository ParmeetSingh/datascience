{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parmeet/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(Mi, Mo):\n",
    "    return np.random.randn(Mi, Mo) / np.sqrt(Mi + Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(None, string.punctuation)\n",
    "def get_robert_frost():\n",
    "    word2idx = {'START': 0, 'END': 1}\n",
    "    current_idx = 2\n",
    "    sentences = []\n",
    "    for line in open('RobertFrost'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            tokens = remove_punctuation(line.lower()).split()\n",
    "            sentence = []\n",
    "            for t in tokens:\n",
    "                if t not in word2idx:\n",
    "                    word2idx[t] = current_idx\n",
    "                    current_idx += 1\n",
    "                idx = word2idx[t]\n",
    "                sentence.append(idx)\n",
    "            sentences.append(sentence)\n",
    "    return sentences, word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b = get_robert_frost()\n",
    "ar = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rnn(object):\n",
    "    def __init__(self,D,M,V):\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "        self.V = V\n",
    "        print \"init done\"\n",
    "    def generate(self,pi,word2idx):\n",
    "        idx2word = {v:k for k,v in word2idx.iteritems()}\n",
    "        V = len(pi)\n",
    "\n",
    "        # generate 4 lines at a time\n",
    "        n_lines = 0\n",
    "\n",
    "        # why? because using the START symbol will always yield the same first word!\n",
    "        X = [ np.random.choice(V, p=pi) ]\n",
    "        print X\n",
    "        print X[0]\n",
    "        print idx2word[X[0]],\n",
    "\n",
    "        while n_lines < 4:\n",
    "            # print \"X:\", X\n",
    "            P = self.predict_op(X)[-1]\n",
    "            X += [P]\n",
    "            if P > 1:\n",
    "                # it's a real word, not start/end token\n",
    "                word = idx2word[P]\n",
    "                print word,\n",
    "            elif P == 1:\n",
    "                # end token\n",
    "                n_lines += 1\n",
    "                print ''\n",
    "                if n_lines < 4:\n",
    "                    X = [ np.random.choice(V, p=pi) ] # reset to start of line\n",
    "                    print idx2word[X[0]],\n",
    "    def fit(self,X,learning_rate=10e-3,mu=0.99,epochs=100,show_fig=True,f=T.nnet.sigmoid):\n",
    "        ## X will be 2-D tuple\n",
    "        \n",
    "        \n",
    "        #defining the weights\n",
    "        #word embedding model\n",
    "        \n",
    "        V = self.V\n",
    "        D = self.D\n",
    "        M = self.M\n",
    "        self.f = f\n",
    "        We_init = init_weight(V,D)\n",
    "        \n",
    "        Wx_init = init_weight(D,M)\n",
    "        Wh_init = init_weight(M,M)\n",
    "        Wo_init = init_weight(M,V)\n",
    "        bo_init = np.zeros(V)\n",
    "        bh_init = np.zeros(M)\n",
    "        h0_init = np.zeros(M)\n",
    "        \n",
    "        \n",
    "        #word embedding model\n",
    "        self.We = theano.shared(We_init)\n",
    "        \n",
    "        self.Wx = theano.shared(Wx_init)\n",
    "        self.Wh = theano.shared(Wh_init)\n",
    "        self.Wo = theano.shared(Wo_init)\n",
    "        self.bo = theano.shared(bo_init)\n",
    "        self.bh = theano.shared(bh_init)\n",
    "        self.h0 = theano.shared(h0_init)\n",
    "        \n",
    "        self.params = [self.We,self.Wx,self.Wh,self.Wo,self.bo,self.bh,self.h0]\n",
    "        \n",
    "        thX = T.ivector('X')\n",
    "        Ei = self.We[thX]\n",
    "        #thE will be TxD matrix\n",
    "        thY = T.ivector('Y')\n",
    "        \n",
    "        def recurrance(X,h_t):\n",
    "            h_t = self.f(X.dot(self.Wx) + h_t.dot(self.Wh) + self.bh)\n",
    "            y_t =  T.nnet.softmax(h_t.dot(self.Wo) + self.bo) \n",
    "            return h_t,y_t\n",
    "        \n",
    "        [h,y],_ = theano.scan(\n",
    "                recurrance, \n",
    "                sequences=Ei, \n",
    "                outputs_info=[self.h0,None], \n",
    "                n_steps=Ei.shape[0]\n",
    "        )\n",
    "        \n",
    "        ##py_x will be TxK matrix\n",
    "        py_x = y[:,0,:]\n",
    "        \n",
    "        cost = -1*T.mean(T.log(py_x[T.arange(thY.shape[0]),thY]))\n",
    "        grad = T.grad(cost,self.params)\n",
    "        \n",
    "        prediction = T.argmax(py_x,axis=1)\n",
    "        \n",
    "        self.dparams = [theano.shared(p.get_value()*0) for p in self.params]\n",
    "        \n",
    "        updates = [(p,p + mu*dp - learning_rate*g) for p,dp,g in zip(self.params,self.dparams,grad)\n",
    "                  ] + [\n",
    "            (dp,mu*dp - learning_rate*g) for dp,g in zip(self.dparams,grad)\n",
    "        ]\n",
    "        \n",
    "        self.train_op = theano.function(\n",
    "            inputs=[thX,thY], \n",
    "            outputs=[cost,prediction],\n",
    "            updates=updates\n",
    "        )\n",
    "        \n",
    "        self.predict_op = theano.function(\n",
    "            inputs = [thX],\n",
    "            outputs=prediction,\n",
    "            allow_input_downcast=True,\n",
    "        )\n",
    "        \n",
    "        costs = []\n",
    "        n_total = sum(len(x) for x in X)\n",
    "        for i in xrange(epochs):\n",
    "            X = shuffle(X)\n",
    "            cost = 0\n",
    "            accuracy=0\n",
    "            for j in a:\n",
    "                input_sequence = [0] + j\n",
    "                output_sequence = j + [1]\n",
    "                c,prediction = self.train_op(input_sequence,output_sequence)\n",
    "                pred = self.predict_op(input_sequence)\n",
    "                #print prediction\n",
    "                cost += c\n",
    "                #print prediction\n",
    "                #print output_sequence\n",
    "                for p,out in zip(prediction,output_sequence):\n",
    "                    if p==out:\n",
    "                        accuracy = accuracy + 1\n",
    "            print \"Cost is\",cost\n",
    "            print \"Accuracy is\",(1.0*accuracy)/n_total\n",
    "            costs.append(cost)\n",
    "        if show_fig==True:\n",
    "            plt.plot(costs)\n",
    "            plt.show()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V = len(b.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "rn = rnn(30,30,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 10851.8001064\n",
      "Accuracy is 0.131205673759\n",
      "Cost is 10021.460598\n",
      "Accuracy is 0.134005225831\n",
      "Cost is 9758.72912346\n",
      "Accuracy is 0.132698768197\n",
      "Cost is 8946.83874299\n",
      "Accuracy is 0.141750653229\n",
      "Cost is 8568.92703825\n",
      "Accuracy is 0.137551325121\n",
      "Cost is 8437.53615025\n",
      "Accuracy is 0.146136618141\n",
      "Cost is 8391.89870646\n",
      "Accuracy is 0.152388951101\n",
      "Cost is 8343.1989443\n",
      "Accuracy is 0.153322135125\n",
      "Cost is 8284.96541692\n",
      "Accuracy is 0.149029488615\n",
      "Cost is 8227.86340903\n",
      "Accuracy is 0.151829040687\n",
      "Cost is 8183.74405577\n",
      "Accuracy is 0.151642403882\n",
      "Cost is 8145.65164815\n",
      "Accuracy is 0.150989175065\n",
      "Cost is 8111.73256261\n",
      "Accuracy is 0.149962672639\n",
      "Cost is 8079.76712001\n",
      "Accuracy is 0.149869354237\n",
      "Cost is 8047.40434533\n",
      "Accuracy is 0.149122807018\n",
      "Cost is 8017.39047025\n",
      "Accuracy is 0.149309443822\n",
      "Cost is 7988.01116484\n",
      "Accuracy is 0.149402762225\n",
      "Cost is 7959.51787166\n",
      "Accuracy is 0.149682717432\n",
      "Cost is 7935.55587954\n",
      "Accuracy is 0.149776035834\n",
      "Cost is 7911.67387271\n",
      "Accuracy is 0.150055991041\n",
      "Cost is 7886.62192591\n",
      "Accuracy is 0.150055991041\n",
      "Cost is 7862.04755669\n",
      "Accuracy is 0.149682717432\n",
      "Cost is 7837.27342774\n",
      "Accuracy is 0.149776035834\n",
      "Cost is 7812.67021626\n",
      "Accuracy is 0.149589399029\n",
      "Cost is 7789.13145192\n",
      "Accuracy is 0.149496080627\n",
      "Cost is 7765.99453177\n",
      "Accuracy is 0.149589399029\n",
      "Cost is 7742.3692211\n",
      "Accuracy is 0.150615901456\n",
      "Cost is 7719.48347551\n",
      "Accuracy is 0.15117581187\n",
      "Cost is 7696.9139056\n",
      "Accuracy is 0.15154908548\n",
      "Cost is 7673.96548786\n",
      "Accuracy is 0.151922359089\n",
      "Cost is 7650.6234908\n",
      "Accuracy is 0.152855543113\n",
      "Cost is 7627.88367481\n",
      "Accuracy is 0.152482269504\n",
      "Cost is 7605.16427762\n",
      "Accuracy is 0.152855543113\n",
      "Cost is 7582.63973568\n",
      "Accuracy is 0.153882045539\n",
      "Cost is 7559.06588614\n",
      "Accuracy is 0.154721911161\n",
      "Cost is 7537.07468324\n",
      "Accuracy is 0.155655095185\n",
      "Cost is 7512.70260694\n",
      "Accuracy is 0.156028368794\n",
      "Cost is 7492.54119228\n",
      "Accuracy is 0.156401642404\n",
      "Cost is 7470.41985073\n",
      "Accuracy is 0.156961552818\n",
      "Cost is 7451.07856159\n",
      "Accuracy is 0.157614781635\n",
      "Cost is 7427.69375564\n",
      "Accuracy is 0.158734602464\n",
      "Cost is 7406.44138681\n",
      "Accuracy is 0.159014557671\n",
      "Cost is 7383.77808786\n",
      "Accuracy is 0.159947741695\n",
      "Cost is 7363.10755092\n",
      "Accuracy is 0.159294512878\n",
      "Cost is 7342.92804021\n",
      "Accuracy is 0.160414333707\n",
      "Cost is 7320.04605942\n",
      "Accuracy is 0.161907428145\n",
      "Cost is 7298.99157655\n",
      "Accuracy is 0.161440836133\n",
      "Cost is 7278.88292343\n",
      "Accuracy is 0.163493840985\n",
      "Cost is 7257.59258568\n",
      "Accuracy is 0.163867114595\n",
      "Cost is 7235.52713617\n",
      "Accuracy is 0.164240388205\n",
      "Cost is 7213.66309972\n",
      "Accuracy is 0.163587159388\n",
      "Cost is 7192.43550422\n",
      "Accuracy is 0.164520343412\n",
      "Cost is 7171.38679057\n",
      "Accuracy is 0.164427025009\n",
      "Cost is 7149.82373725\n",
      "Accuracy is 0.164333706607\n",
      "Cost is 7128.23183407\n",
      "Accuracy is 0.1640537514\n",
      "Cost is 7106.93930505\n",
      "Accuracy is 0.16601343785\n",
      "Cost is 7082.93226988\n",
      "Accuracy is 0.166386711459\n",
      "Cost is 7063.56853584\n",
      "Accuracy is 0.166573348264\n",
      "Cost is 7040.87133836\n",
      "Accuracy is 0.166666666667\n",
      "Cost is 7019.84583518\n",
      "Accuracy is 0.166480029862\n",
      "Cost is 6997.80417962\n",
      "Accuracy is 0.167319895483\n",
      "Cost is 6973.86933611\n",
      "Accuracy is 0.168066442703\n",
      "Cost is 6953.89286041\n",
      "Accuracy is 0.168999626726\n",
      "Cost is 6933.20548912\n",
      "Accuracy is 0.169279581934\n",
      "Cost is 6912.26912003\n",
      "Accuracy is 0.169372900336\n",
      "Cost is 6890.99386669\n",
      "Accuracy is 0.171052631579\n",
      "Cost is 6868.6204336\n",
      "Accuracy is 0.171425905189\n",
      "Cost is 6850.50749931\n",
      "Accuracy is 0.171425905189\n",
      "Cost is 6830.12266696\n",
      "Accuracy is 0.170772676372\n",
      "Cost is 6812.25144483\n",
      "Accuracy is 0.171145949981\n",
      "Cost is 6787.76608452\n",
      "Accuracy is 0.171332586786\n",
      "Cost is 6767.13075318\n",
      "Accuracy is 0.171052631579\n",
      "Cost is 6746.65455281\n",
      "Accuracy is 0.171239268384\n",
      "Cost is 6726.38828681\n",
      "Accuracy is 0.172918999627\n",
      "Cost is 6703.55919419\n",
      "Accuracy is 0.173665546846\n",
      "Cost is 6680.93700324\n",
      "Accuracy is 0.174038820455\n",
      "Cost is 6660.45311502\n",
      "Accuracy is 0.173478910041\n",
      "Cost is 6639.00600331\n",
      "Accuracy is 0.173852183651\n",
      "Cost is 6617.19355701\n",
      "Accuracy is 0.174878686077\n",
      "Cost is 6595.85198204\n",
      "Accuracy is 0.176278462113\n",
      "Cost is 6572.78275552\n",
      "Accuracy is 0.175625233296\n",
      "Cost is 6552.61904561\n",
      "Accuracy is 0.177211646137\n",
      "Cost is 6529.48442084\n",
      "Accuracy is 0.177771556551\n",
      "Cost is 6506.44426831\n",
      "Accuracy is 0.178051511758\n",
      "Cost is 6482.98921895\n",
      "Accuracy is 0.177958193356\n",
      "Cost is 6465.26103523\n",
      "Accuracy is 0.179171332587\n",
      "Cost is 6444.28392493\n",
      "Accuracy is 0.179264650989\n",
      "Cost is 6424.17502116\n",
      "Accuracy is 0.179637924599\n",
      "Cost is 6404.21961818\n",
      "Accuracy is 0.18047779022\n",
      "Cost is 6382.84088992\n",
      "Accuracy is 0.181504292647\n",
      "Cost is 6365.12132492\n",
      "Accuracy is 0.180757745427\n",
      "Cost is 6348.48439815\n",
      "Accuracy is 0.181597611049\n",
      "Cost is 6328.952896\n",
      "Accuracy is 0.181224337439\n",
      "Cost is 6309.53606214\n",
      "Accuracy is 0.181131019037\n",
      "Cost is 6291.6219086\n",
      "Accuracy is 0.181784247854\n",
      "Cost is 6274.09289375\n",
      "Accuracy is 0.182997387085\n",
      "Cost is 6258.90472758\n",
      "Accuracy is 0.183743934304\n",
      "Cost is 6245.33890315\n",
      "Accuracy is 0.184863755133\n",
      "Cost is 6229.72244419\n",
      "Accuracy is 0.184957073535\n",
      "Cost is 6218.35706288\n",
      "Accuracy is 0.185423665547\n",
      "Cost is 6202.9371561\n",
      "Accuracy is 0.185983575961\n",
      "Cost is 6188.62684527\n",
      "Accuracy is 0.188129899216\n",
      "Cost is 6173.40361429\n",
      "Accuracy is 0.188036580814\n",
      "Cost is 6161.37198137\n",
      "Accuracy is 0.188129899216\n",
      "Cost is 6148.69331185\n",
      "Accuracy is 0.188129899216\n",
      "Cost is 6135.41062606\n",
      "Accuracy is 0.18906308324\n",
      "Cost is 6118.42468336\n",
      "Accuracy is 0.190369540873\n",
      "Cost is 6104.25308237\n",
      "Accuracy is 0.190182904069\n",
      "Cost is 6085.42673721\n",
      "Accuracy is 0.190089585666\n",
      "Cost is 6073.16537301\n",
      "Accuracy is 0.191675998507\n",
      "Cost is 6052.72928393\n",
      "Accuracy is 0.192795819336\n",
      "Cost is 6031.6368537\n",
      "Accuracy is 0.19298245614\n",
      "Cost is 6010.89090608\n",
      "Accuracy is 0.194288913774\n",
      "Cost is 5997.65490559\n",
      "Accuracy is 0.194942142591\n",
      "Cost is 5977.21842693\n",
      "Accuracy is 0.196621873834\n",
      "Cost is 5958.37943187\n",
      "Accuracy is 0.196621873834\n",
      "Cost is 5946.3019491\n",
      "Accuracy is 0.197181784248\n",
      "Cost is 5933.65317321\n",
      "Accuracy is 0.199888017917\n",
      "Cost is 5922.09089866\n",
      "Accuracy is 0.199421425905\n",
      "Cost is 5905.7972763\n",
      "Accuracy is 0.199421425905\n",
      "Cost is 5897.55375663\n",
      "Accuracy is 0.19998133632\n",
      "Cost is 5883.71866182\n",
      "Accuracy is 0.202220977977\n",
      "Cost is 5870.76187805\n",
      "Accuracy is 0.202220977977\n",
      "Cost is 5856.04203885\n",
      "Accuracy is 0.202874206794\n",
      "Cost is 5840.89823764\n",
      "Accuracy is 0.204553938037\n",
      "Cost is 5832.82871066\n",
      "Accuracy is 0.203714072415\n",
      "Cost is 5818.81530249\n",
      "Accuracy is 0.205673758865\n",
      "Cost is 5804.1623222\n",
      "Accuracy is 0.205300485256\n",
      "Cost is 5787.28293932\n",
      "Accuracy is 0.208473310937\n",
      "Cost is 5775.02107767\n",
      "Accuracy is 0.208286674132\n",
      "Cost is 5763.4873513\n",
      "Accuracy is 0.209126539754\n",
      "Cost is 5752.13361116\n",
      "Accuracy is 0.210806270997\n",
      "Cost is 5740.23065765\n",
      "Accuracy is 0.211926091825\n",
      "Cost is 5725.16734969\n",
      "Accuracy is 0.212019410228\n",
      "Cost is 5717.16848688\n",
      "Accuracy is 0.214352370287\n",
      "Cost is 5710.42430631\n",
      "Accuracy is 0.212952594252\n",
      "Cost is 5711.11927161\n",
      "Accuracy is 0.214539007092\n",
      "Cost is 5701.1940207\n",
      "Accuracy is 0.211832773423\n",
      "Cost is 5693.04868732\n",
      "Accuracy is 0.213605823068\n",
      "Cost is 5691.52095261\n",
      "Accuracy is 0.214632325495\n",
      "Cost is 5702.00775534\n",
      "Accuracy is 0.210059723778\n",
      "Cost is 5688.6598588\n",
      "Accuracy is 0.213232549459\n",
      "Cost is 5677.47951821\n",
      "Accuracy is 0.213325867861\n",
      "Cost is 5674.26970851\n",
      "Accuracy is 0.21407241508\n",
      "Cost is 5665.11900928\n",
      "Accuracy is 0.214539007092\n",
      "Cost is 5645.7087927\n",
      "Accuracy is 0.215192235909\n",
      "Cost is 5640.54496885\n",
      "Accuracy is 0.215938783128\n",
      "Cost is 5629.97563292\n",
      "Accuracy is 0.219018290407\n",
      "Cost is 5626.44583715\n",
      "Accuracy is 0.219391564016\n",
      "Cost is 5615.56074396\n",
      "Accuracy is 0.220604703247\n",
      "Cost is 5591.87427746\n",
      "Accuracy is 0.223684210526\n",
      "Cost is 5568.97545444\n",
      "Accuracy is 0.22499066816\n",
      "Cost is 5545.6046193\n",
      "Accuracy is 0.22695035461\n",
      "Cost is 5527.81859458\n",
      "Accuracy is 0.225923852184\n",
      "Cost is 5506.77814762\n",
      "Accuracy is 0.230683090705\n",
      "Cost is 5494.19520896\n",
      "Accuracy is 0.231056364315\n",
      "Cost is 5477.58735277\n",
      "Accuracy is 0.232269503546\n",
      "Cost is 5457.56638881\n",
      "Accuracy is 0.234975737215\n",
      "Cost is 5438.75184208\n",
      "Accuracy is 0.236002239642\n",
      "Cost is 5423.92423647\n",
      "Accuracy is 0.237775289287\n",
      "Cost is 5412.67530136\n",
      "Accuracy is 0.238241881299\n",
      "Cost is 5395.89604742\n",
      "Accuracy is 0.239734975737\n",
      "Cost is 5389.1806673\n",
      "Accuracy is 0.240948114968\n",
      "Cost is 5379.25636952\n",
      "Accuracy is 0.24178798059\n",
      "Cost is 5366.71967678\n",
      "Accuracy is 0.24374766704\n",
      "Cost is 5357.34161392\n",
      "Accuracy is 0.245520716685\n",
      "Cost is 5348.51146876\n",
      "Accuracy is 0.244120940649\n",
      "Cost is 5330.47716715\n",
      "Accuracy is 0.248600223964\n",
      "Cost is 5322.27091453\n",
      "Accuracy is 0.247573721538\n",
      "Cost is 5309.98180185\n",
      "Accuracy is 0.247013811124\n",
      "Cost is 5293.02814565\n",
      "Accuracy is 0.249253452781\n",
      "Cost is 5285.12523263\n",
      "Accuracy is 0.248226950355\n",
      "Cost is 5276.04763481\n",
      "Accuracy is 0.249813363195\n",
      "Cost is 5260.38575134\n",
      "Accuracy is 0.252239641657\n",
      "Cost is 5249.44933693\n",
      "Accuracy is 0.252426278462\n",
      "Cost is 5239.19584223\n",
      "Accuracy is 0.252053004853\n",
      "Cost is 5236.11410347\n",
      "Accuracy is 0.252706233669\n",
      "Cost is 5244.36689716\n",
      "Accuracy is 0.253172825681\n",
      "Cost is 5230.56471073\n",
      "Accuracy is 0.254852556924\n",
      "Cost is 5235.3787632\n",
      "Accuracy is 0.255692422546\n",
      "Cost is 5226.8953442\n",
      "Accuracy is 0.255412467339\n",
      "Cost is 5211.04128182\n",
      "Accuracy is 0.256718924972\n",
      "Cost is 5224.77272218\n",
      "Accuracy is 0.256065696155\n",
      "Cost is 5223.46282921\n",
      "Accuracy is 0.257652108996\n",
      "Cost is 5216.19648769\n",
      "Accuracy is 0.255505785741\n",
      "Cost is 5209.49839473\n",
      "Accuracy is 0.258118701008\n",
      "Cost is 5221.16151116\n",
      "Accuracy is 0.257838745801\n",
      "Cost is 5238.06836138\n",
      "Accuracy is 0.25429264651\n",
      "Cost is 5225.97186552\n",
      "Accuracy is 0.252146323255\n",
      "Cost is 5202.7896667\n",
      "Accuracy is 0.257092198582\n",
      "Cost is 5188.0473689\n",
      "Accuracy is 0.261291526689\n",
      "Cost is 5154.91210099\n",
      "Accuracy is 0.26642403882\n",
      "Cost is 5154.08779253\n",
      "Accuracy is 0.265210899589\n",
      "Cost is 5154.59894378\n",
      "Accuracy is 0.263624486749\n",
      "Cost is 5141.28335163\n",
      "Accuracy is 0.266050765211\n",
      "Cost is 5120.53051919\n",
      "Accuracy is 0.268570362075\n",
      "Cost is 5117.63443818\n",
      "Accuracy is 0.264371033968\n",
      "Cost is 5097.31628701\n",
      "Accuracy is 0.267823814856\n",
      "Cost is 5079.83659781\n",
      "Accuracy is 0.272396416573\n",
      "Cost is 5071.58862742\n",
      "Accuracy is 0.273516237402\n",
      "Cost is 5063.36357825\n",
      "Accuracy is 0.275195968645\n",
      "Cost is 5036.14951127\n",
      "Accuracy is 0.277622247107\n",
      "Cost is 5033.2046788\n",
      "Accuracy is 0.277995520717\n",
      "Cost is 5034.31035918\n",
      "Accuracy is 0.2773422919\n",
      "Cost is 5020.88109411\n",
      "Accuracy is 0.277248973498\n",
      "Cost is 4985.0919299\n",
      "Accuracy is 0.284527808884\n",
      "Cost is 5010.60991665\n",
      "Accuracy is 0.279768570362\n",
      "Cost is 4996.64405432\n",
      "Accuracy is 0.281075027996\n",
      "Cost is 4967.30173823\n",
      "Accuracy is 0.285181037701\n",
      "Cost is 4972.26542449\n",
      "Accuracy is 0.283128032848\n",
      "Cost is 5007.88272227\n",
      "Accuracy is 0.280235162374\n",
      "Cost is 4996.76879198\n",
      "Accuracy is 0.278928704741\n",
      "Cost is 4964.20580471\n",
      "Accuracy is 0.284621127286\n",
      "Cost is 4968.55978457\n",
      "Accuracy is 0.285087719298\n",
      "Cost is 4954.17689321\n",
      "Accuracy is 0.284901082493\n",
      "Cost is 4962.70361523\n",
      "Accuracy is 0.285274356103\n",
      "Cost is 4961.73173333\n",
      "Accuracy is 0.285460992908\n",
      "Cost is 4952.77758579\n",
      "Accuracy is 0.287793952968\n",
      "Cost is 4972.94711068\n",
      "Accuracy is 0.281541620007\n",
      "Cost is 4949.80963535\n",
      "Accuracy is 0.287607316163\n",
      "Cost is 4982.13255769\n",
      "Accuracy is 0.280235162374\n",
      "Cost is 4972.90429742\n",
      "Accuracy is 0.282194848824\n",
      "Cost is 4964.36118174\n",
      "Accuracy is 0.283314669653\n",
      "Cost is 4975.74073543\n",
      "Accuracy is 0.286394176932\n",
      "Cost is 4959.46177082\n",
      "Accuracy is 0.287700634565\n",
      "Cost is 4956.55778934\n",
      "Accuracy is 0.288633818589\n",
      "Cost is 4933.28711777\n",
      "Accuracy is 0.292459873087\n",
      "Cost is 4922.51638396\n",
      "Accuracy is 0.290033594625\n",
      "Cost is 4914.24498243\n",
      "Accuracy is 0.29413960433\n",
      "Cost is 4912.1079255\n",
      "Accuracy is 0.295539380366\n",
      "Cost is 4921.23936365\n",
      "Accuracy is 0.294419559537\n",
      "Cost is 4908.14160484\n",
      "Accuracy is 0.295166106756\n",
      "Cost is 4901.53331924\n",
      "Accuracy is 0.299272116461\n",
      "Cost is 4935.8806843\n",
      "Accuracy is 0.291899962673\n",
      "Cost is 4945.50722369\n",
      "Accuracy is 0.290406868234\n",
      "Cost is 4937.41173099\n",
      "Accuracy is 0.292553191489\n",
      "Cost is 4946.27394137\n",
      "Accuracy is 0.287980589772\n",
      "Cost is 4926.95800822\n",
      "Accuracy is 0.291153415454\n",
      "Cost is 4895.80713672\n",
      "Accuracy is 0.294419559537\n",
      "Cost is 4897.86256058\n",
      "Accuracy is 0.295352743561\n",
      "Cost is 4893.58698632\n",
      "Accuracy is 0.298338932437\n",
      "Cost is 4864.9020663\n",
      "Accuracy is 0.301418439716\n",
      "Cost is 4854.61901308\n",
      "Accuracy is 0.301325121314\n",
      "Cost is 4863.09366132\n",
      "Accuracy is 0.302164986935\n",
      "Cost is 4861.21413442\n",
      "Accuracy is 0.301418439716\n",
      "Cost is 4839.81540366\n",
      "Accuracy is 0.303098170959\n",
      "Cost is 4844.35943087\n",
      "Accuracy is 0.305617767824\n",
      "Cost is 4828.55708163\n",
      "Accuracy is 0.308230683091\n",
      "Cost is 4813.43377748\n",
      "Accuracy is 0.306737588652\n",
      "Cost is 4792.88721874\n",
      "Accuracy is 0.307950727884\n",
      "Cost is 4778.24660023\n",
      "Accuracy is 0.313923105636\n",
      "Cost is 4775.2092787\n",
      "Accuracy is 0.310843598358\n",
      "Cost is 4759.03939529\n",
      "Accuracy is 0.312056737589\n",
      "Cost is 4790.50423369\n",
      "Accuracy is 0.308790593505\n",
      "Cost is 4721.48304108\n",
      "Accuracy is 0.319335572975\n",
      "Cost is 4705.40770866\n",
      "Accuracy is 0.32110862262\n",
      "Cost is 4703.01800486\n",
      "Accuracy is 0.319242254573\n",
      "Cost is 4668.70010121\n",
      "Accuracy is 0.325494587533\n",
      "Cost is 4655.01091403\n",
      "Accuracy is 0.324934677118\n",
      "Cost is 4655.87008272\n",
      "Accuracy is 0.327827547592\n",
      "Cost is 4653.32797386\n",
      "Accuracy is 0.325587905935\n",
      "Cost is 4650.97232133\n",
      "Accuracy is 0.32773422919\n",
      "Cost is 4636.14417084\n",
      "Accuracy is 0.328574094811\n",
      "Cost is 4616.74360384\n",
      "Accuracy is 0.329320642031\n",
      "Cost is 4611.57457606\n",
      "Accuracy is 0.333613288541\n",
      "Cost is 4578.46457867\n",
      "Accuracy is 0.336039567003\n",
      "Cost is 4586.50640711\n",
      "Accuracy is 0.335293019784\n",
      "Cost is 4572.30151138\n",
      "Accuracy is 0.339119074281\n",
      "Cost is 4553.16731085\n",
      "Accuracy is 0.339305711086\n",
      "Cost is 4551.72641389\n",
      "Accuracy is 0.339025755879\n",
      "Cost is 4554.55113769\n",
      "Accuracy is 0.335199701381\n",
      "Cost is 4537.22928617\n",
      "Accuracy is 0.34061216872\n",
      "Cost is 4519.03363882\n",
      "Accuracy is 0.346957820082\n",
      "Cost is 4536.0783067\n",
      "Accuracy is 0.342851810377\n",
      "Cost is 4507.17399328\n",
      "Accuracy is 0.347144456887\n",
      "Cost is 4528.07425359\n",
      "Accuracy is 0.342665173572\n",
      "Cost is 4514.45013732\n",
      "Accuracy is 0.345278088839\n",
      "Cost is 4503.30796559\n",
      "Accuracy is 0.346117954461\n",
      "Cost is 4488.34529687\n",
      "Accuracy is 0.347237775289\n",
      "Cost is 4497.27635716\n",
      "Accuracy is 0.347704367301\n",
      "Cost is 4504.37910789\n",
      "Accuracy is 0.343784994401\n",
      "Cost is 4471.46698694\n",
      "Accuracy is 0.352183650616\n",
      "Cost is 4499.80022895\n",
      "Accuracy is 0.345931317656\n",
      "Cost is 4503.05926971\n",
      "Accuracy is 0.347704367301\n",
      "Cost is 4490.4643673\n",
      "Accuracy is 0.34649122807\n",
      "Cost is 4465.76175912\n",
      "Accuracy is 0.351250466592\n",
      "Cost is 4476.82449582\n",
      "Accuracy is 0.352463605823\n",
      "Cost is 4454.06307654\n",
      "Accuracy is 0.356196341919\n",
      "Cost is 4463.26999587\n",
      "Accuracy is 0.350597237775\n",
      "Cost is 4493.86987734\n",
      "Accuracy is 0.348637551325\n",
      "Cost is 4468.59672169\n",
      "Accuracy is 0.353303471445\n",
      "Cost is 4507.01257351\n",
      "Accuracy is 0.349290780142\n",
      "Cost is 4438.77756222\n",
      "Accuracy is 0.360022396417\n",
      "Cost is 4445.73950089\n",
      "Accuracy is 0.354423292273\n",
      "Cost is 4473.20031272\n",
      "Accuracy is 0.352370287421\n",
      "Cost is 4483.15542044\n",
      "Accuracy is 0.349104143337\n",
      "Cost is 4493.62104612\n",
      "Accuracy is 0.350223964166\n",
      "Cost is 4431.60410089\n",
      "Accuracy is 0.356382978723\n",
      "Cost is 4439.35835267\n",
      "Accuracy is 0.358529301978\n",
      "Cost is 4511.25389791\n",
      "Accuracy is 0.345371407242\n",
      "Cost is 4411.68797422\n",
      "Accuracy is 0.356476297126\n",
      "Cost is 4391.57685514\n",
      "Accuracy is 0.362821948488\n",
      "Cost is 4433.58114445\n",
      "Accuracy is 0.356289660321\n",
      "Cost is 4393.31664717\n",
      "Accuracy is 0.361982082867\n",
      "Cost is 4412.31271277\n",
      "Accuracy is 0.360582306831\n",
      "Cost is 4333.1441649\n",
      "Accuracy is 0.364874953341\n",
      "Cost is 4326.77688423\n",
      "Accuracy is 0.371033967898\n",
      "Cost is 4308.52620812\n",
      "Accuracy is 0.372713699141\n",
      "Cost is 4324.97619888\n",
      "Accuracy is 0.370660694289\n",
      "Cost is 4326.44170405\n",
      "Accuracy is 0.371033967898\n",
      "Cost is 4351.41924906\n",
      "Accuracy is 0.366741321389\n",
      "Cost is 4330.3517021\n",
      "Accuracy is 0.369820828667\n",
      "Cost is 4281.7851355\n",
      "Accuracy is 0.377099664054\n",
      "Cost is 4275.75663251\n",
      "Accuracy is 0.376073161627\n",
      "Cost is 4260.17428257\n",
      "Accuracy is 0.380925718552\n",
      "Cost is 4292.03525207\n",
      "Accuracy is 0.377192982456\n",
      "Cost is 4294.29625337\n",
      "Accuracy is 0.37616648003\n",
      "Cost is 4245.29908295\n",
      "Accuracy is 0.382512131392\n",
      "Cost is 4222.90930811\n",
      "Accuracy is 0.385218365062\n",
      "Cost is 4277.37073139\n",
      "Accuracy is 0.377192982456\n",
      "Cost is 4227.38182404\n",
      "Accuracy is 0.385405001866\n",
      "Cost is 4202.05243746\n",
      "Accuracy is 0.388484509145\n",
      "Cost is 4179.47182952\n",
      "Accuracy is 0.393803658081\n",
      "Cost is 4204.31102104\n",
      "Accuracy is 0.388017917133\n",
      "Cost is 4217.45064844\n",
      "Accuracy is 0.386991414707\n",
      "Cost is 4206.00226394\n",
      "Accuracy is 0.385871593878\n",
      "Cost is 4268.26396649\n",
      "Accuracy is 0.379619260918\n",
      "Cost is 4264.4105488\n",
      "Accuracy is 0.379992534528\n",
      "Cost is 4237.41268852\n",
      "Accuracy is 0.382978723404\n",
      "Cost is 4261.54287754\n",
      "Accuracy is 0.382698768197\n",
      "Cost is 4256.54486793\n",
      "Accuracy is 0.384285181038\n",
      "Cost is 4255.63401982\n",
      "Accuracy is 0.383911907428\n",
      "Cost is 4235.66031924\n",
      "Accuracy is 0.38475177305\n",
      "Cost is 4248.12160411\n",
      "Accuracy is 0.383538633819\n",
      "Cost is 4263.61514063\n",
      "Accuracy is 0.37579320642\n",
      "Cost is 4240.61052644\n",
      "Accuracy is 0.381952220978\n",
      "Cost is 4202.98422806\n",
      "Accuracy is 0.39296379246\n",
      "Cost is 4191.83144898\n",
      "Accuracy is 0.394643523703\n",
      "Cost is 4172.04290852\n",
      "Accuracy is 0.393803658081\n",
      "Cost is 4202.6806931\n",
      "Accuracy is 0.389231056364\n",
      "Cost is 4166.22820451\n",
      "Accuracy is 0.39259051885\n",
      "Cost is 4180.85066022\n",
      "Accuracy is 0.390537513998\n",
      "Cost is 4179.50778244\n",
      "Accuracy is 0.393337066069\n",
      "Cost is 4219.10838981\n",
      "Accuracy is 0.387458006719\n",
      "Cost is 4189.84037114\n",
      "Accuracy is 0.395016797312\n",
      "Cost is 4167.2641953\n",
      "Accuracy is 0.397069802165\n",
      "Cost is 4151.08753966\n",
      "Accuracy is 0.402108995894\n",
      "Cost is 4156.70271468\n",
      "Accuracy is 0.400429264651\n",
      "Cost is 4130.29548164\n",
      "Accuracy is 0.405561776782\n",
      "Cost is 4144.82970248\n",
      "Accuracy is 0.399962672639\n",
      "Cost is 4164.20417672\n",
      "Accuracy is 0.394176931691\n",
      "Cost is 4157.95842591\n",
      "Accuracy is 0.392683837253\n",
      "Cost is 4125.87606235\n",
      "Accuracy is 0.401829040687\n",
      "Cost is 4113.88206045\n",
      "Accuracy is 0.403882045539\n",
      "Cost is 4112.86013781\n",
      "Accuracy is 0.40509518477\n",
      "Cost is 4132.53407178\n",
      "Accuracy is 0.401922359089\n",
      "Cost is 4176.14038829\n",
      "Accuracy is 0.391843971631\n",
      "Cost is 4149.59264364\n",
      "Accuracy is 0.400149309444\n",
      "Cost is 4103.99226153\n",
      "Accuracy is 0.403882045539\n",
      "Cost is 4104.33799574\n",
      "Accuracy is 0.407614781635\n",
      "Cost is 4080.68543312\n",
      "Accuracy is 0.407521463233\n",
      "Cost is 4063.00987107\n",
      "Accuracy is 0.409667786487\n",
      "Cost is 4078.39728482\n",
      "Accuracy is 0.40976110489\n",
      "Cost is 4074.84085552\n",
      "Accuracy is 0.406588279209\n",
      "Cost is 4065.16883512\n",
      "Accuracy is 0.413213885778\n",
      "Cost is 4072.1480762\n",
      "Accuracy is 0.409481149683\n",
      "Cost is 4108.91180478\n",
      "Accuracy is 0.403602090332\n",
      "Cost is 4094.24669648\n",
      "Accuracy is 0.401922359089\n",
      "Cost is 4100.88727281\n",
      "Accuracy is 0.401735722284\n",
      "Cost is 4099.03931899\n",
      "Accuracy is 0.403228816723\n",
      "Cost is 4057.13088594\n",
      "Accuracy is 0.409201194476\n",
      "Cost is 4034.70034437\n",
      "Accuracy is 0.415826801045\n",
      "Cost is 4030.6872247\n",
      "Accuracy is 0.413120567376\n",
      "Cost is 4046.813058\n",
      "Accuracy is 0.41134751773\n",
      "Cost is 4060.54622504\n",
      "Accuracy is 0.409947741695\n",
      "Cost is 4029.5522741\n",
      "Accuracy is 0.413400522583\n",
      "Cost is 4032.76986776\n",
      "Accuracy is 0.412374020157\n",
      "Cost is 4038.78780337\n",
      "Accuracy is 0.414706980216\n",
      "Cost is 4072.26374938\n",
      "Accuracy is 0.40350877193\n",
      "Cost is 4040.93796204\n",
      "Accuracy is 0.410321015304\n",
      "Cost is 4040.68290167\n",
      "Accuracy is 0.408827920866\n",
      "Cost is 4002.94370762\n",
      "Accuracy is 0.416666666667\n",
      "Cost is 3999.67156631\n",
      "Accuracy is 0.412560656962\n",
      "Cost is 3998.62272503\n",
      "Accuracy is 0.415920119448\n",
      "Cost is 4006.79264764\n",
      "Accuracy is 0.414613661814\n",
      "Cost is 3997.05619508\n",
      "Accuracy is 0.416106756252\n",
      "Cost is 4009.85098944\n",
      "Accuracy is 0.412467338559\n",
      "Cost is 3999.28333704\n",
      "Accuracy is 0.414986935424\n",
      "Cost is 3991.82521001\n",
      "Accuracy is 0.418066442703\n",
      "Cost is 3970.69961818\n",
      "Accuracy is 0.421705860396\n",
      "Cost is 3944.77006993\n",
      "Accuracy is 0.427211646137\n",
      "Cost is 3942.75537191\n",
      "Accuracy is 0.425158641284\n",
      "Cost is 4008.19464225\n",
      "Accuracy is 0.415173572228\n",
      "Cost is 4071.84964304\n",
      "Accuracy is 0.402108995894\n",
      "Cost is 4009.59019005\n",
      "Accuracy is 0.417226577081\n",
      "Cost is 3970.67693892\n",
      "Accuracy is 0.422918999627\n",
      "Cost is 3950.58572441\n",
      "Accuracy is 0.425345278089\n",
      "Cost is 3944.88424389\n",
      "Accuracy is 0.421332586786\n",
      "Cost is 3954.80117048\n",
      "Accuracy is 0.425531914894\n",
      "Cost is 3950.80540922\n",
      "Accuracy is 0.424132138858\n",
      "Cost is 3984.28633297\n",
      "Accuracy is 0.417506532288\n",
      "Cost is 3974.01647001\n",
      "Accuracy is 0.414800298619\n",
      "Cost is 3923.71815088\n",
      "Accuracy is 0.426838372527\n",
      "Cost is 3934.05520727\n",
      "Accuracy is 0.423478910041\n",
      "Cost is 3895.40474329\n",
      "Accuracy is 0.429078014184\n",
      "Cost is 3905.3605673\n",
      "Accuracy is 0.428704740575\n",
      "Cost is 3922.67498813\n",
      "Accuracy is 0.422545726017\n",
      "Cost is 3911.08873551\n",
      "Accuracy is 0.426838372527\n",
      "Cost is 3897.476796\n",
      "Accuracy is 0.429731243001\n",
      "Cost is 3993.55076336\n",
      "Accuracy is 0.411067562523\n",
      "Cost is 3959.5551297\n",
      "Accuracy is 0.420679357969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-8fc862893715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-348-4c0fd5201b27>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, learning_rate, mu, epochs, show_fig, f)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0minput_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0moutput_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[1;31m#print prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\scan_module\\scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\scan_module\\scan_op.pyc\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\parmeets\\AppData\\Local\\Theano\\compiledir_Windows-7-6.1.7601-SP1-Intel64_Family_6_Model_78_Stepping_3_GenuineIntel-2.7.13-64\\scan_perform\\mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\tensor\\blas.pyc\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, out_storage)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[1;31m#                         overwrite_y=self.inplace)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             out_storage[0][0] = gemv(alpha, A.T, x, beta, y,\n\u001b[0;32m--> 270\u001b[0;31m                                      overwrite_y=self.inplace, trans=True)\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rn.fit(a,epochs=6000,f=T.nnet.relu,learning_rate=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = a\n",
    "V = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = np.zeros(V)\n",
    "for sentence in sentences:\n",
    "    pi[sentence[0]] += 1 \n",
    "pi = pi/pi.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29L]\n",
      "29\n",
      "the one range \n",
      "thats the voices have man \n",
      "a one descent with the step \n",
      "inscription but isnt her to be \n"
     ]
    }
   ],
   "source": [
    "rn.generate(pi,word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'END'"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = {value:key for key,value in word2idx.iteritems()}\n",
    "m[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sequence too large; cannot be greater than 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-0420635fbd2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy\\random\\mtrand\\mtrand.c:17437)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint (numpy\\random\\mtrand\\mtrand.c:15790)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint (numpy\\random\\mtrand\\mtrand.c:15595)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand._rand_int32 (numpy\\random\\mtrand\\mtrand.c:10408)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sequence too large; cannot be greater than 32"
     ]
    }
   ],
   "source": [
    "np.random.choice(V,pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in word2idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-321-602795223340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "idx2word[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

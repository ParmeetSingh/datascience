{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weight(Wi,Wo):\n",
    "    return np.random.randn(Wi,Wo)/ np.sqrt(Wi+Wo)\n",
    "def get_robert_frost():\n",
    "    word2idx = {\"START\":0,\"END\":1}\n",
    "    sentences = []\n",
    "    current = 2\n",
    "    with open('RobertFrost') as f:\n",
    "        for line in f:\n",
    "            line  = line.strip()\n",
    "            if line:\n",
    "                sentence = []\n",
    "                line = line.translate(None, string.punctuation)\n",
    "                for word in line.split():\n",
    "                    if word not in word2idx:\n",
    "                        word2idx[word] = current\n",
    "                        current = current + 1\n",
    "                    sentence.append(word2idx[word])\n",
    "                sentences.append(sentence)\n",
    "    return sentences,word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences,vocabulary = get_robert_frost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class lstm():\n",
    "    def __init__(self,H,D,V):\n",
    "        # number of hidden units\n",
    "        self.H = H\n",
    "        #dimension of the word embedding model\n",
    "        self.D = D\n",
    "        #vocabulary size model\n",
    "        self.V = V\n",
    "    def layer_init_weight(self):\n",
    "        Wlx_init = init_weight(self.D,self.H)\n",
    "        Wlh_init = init_weight(self.H,self.H)\n",
    "        blh_init = np.zeros(self.H)\n",
    "        \n",
    "        thWlx = theano.shared(Wlx_init)\n",
    "        thWlh = theano.shared(Wlh_init)\n",
    "        thblh = theano.shared(blh_init)\n",
    "        \n",
    "        return thWlx,thWlh,thblh\n",
    "    def set_lstm_variables(self):\n",
    "        \n",
    "        self.C0 = theano.shared(np.zeros(self.H))\n",
    "        self.h0 = theano.shared(np.zeros(self.H))\n",
    "        \n",
    "        self.Wfx,self.Wfh,self.bfh = self.layer_init_weight()\n",
    "        self.Wix,self.Wih,self.bih = self.layer_init_weight()\n",
    "        self.WCx,self.WCh,self.bCh = self.layer_init_weight()\n",
    "        self.Wox,self.Woh,self.boh = self.layer_init_weight()\n",
    "    \n",
    "    def set_variables(self):\n",
    "        \n",
    "        thX = T.ivector('thX')\n",
    "        thY = T.ivector('thY')\n",
    "        Ei = self.We[thX]\n",
    "        \n",
    "        \n",
    "        #will set all lstm variable in instance variable params\n",
    "        #will also set dparams variable\n",
    "        self.params = [self.We,self.C0,self.h0,self.Wfx,self.Wfh,self.bfh,self.Wix,self.Wih,self.bih,\n",
    "                      self.WCx,self.WCh,self.bCh,self.Wox,self.Woh,self.boh,self.Wo,self.bo]\n",
    "        \n",
    "        def recurrance(x_t,h_t1,C_t1):\n",
    "            ft = T.nnet.sigmoid(x_t.dot(self.Wfx)+ h_t1.dot(self.Wfh) + self.bfh)\n",
    "            it = T.nnet.sigmoid(x_t.dot(self.Wix)+ h_t1.dot(self.Wih) + self.bih)\n",
    "            Cdasht = T.tanh(x_t.dot(self.WCx)+ h_t1.dot(self.WCh) + self.bCh)\n",
    "            ot = T.nnet.sigmoid(x_t.dot(self.Wox)+ h_t1.dot(self.Woh) + self.boh)\n",
    "            C_t = ft*C_t1 + it*Cdasht\n",
    "            ot = T.nnet.sigmoid(x_t.dot(self.Wox)+ h_t1.dot(self.Woh) + self.boh)\n",
    "            h_t = ot*T.tanh(C_t)\n",
    "            return h_t,C_t\n",
    "        \n",
    "        #forward run of sequence\n",
    "        [h,C],_ = theano.scan(\n",
    "                                fn = recurrance,\n",
    "                                sequences=Ei,\n",
    "                                outputs_info=[self.h0,self.C0],\n",
    "                                n_steps=Ei.shape[0]\n",
    "                            )\n",
    "        \n",
    "        py_x = T.nnet.softmax(h.dot(self.Wo) + self.bo)\n",
    "        \n",
    "        prediction = T.argmax(py_x,axis=1)\n",
    "        \n",
    "        self.predict = theano.function(\n",
    "            inputs = [thX],\n",
    "            outputs = [prediction]\n",
    "        )\n",
    "    \n",
    "    def fit(self,X,alpha=10e-5,mu=0.99,print_period=10,epochs=1):\n",
    "        \n",
    "        We_init = init_weight(self.V,self.D)\n",
    "        self.We = theano.shared(We_init)\n",
    "        \n",
    "        thX = T.ivector('thX')\n",
    "        thY = T.ivector('thY')\n",
    "        Ei = self.We[thX]\n",
    "        \n",
    "        \n",
    "        self.set_lstm_variables()\n",
    "        ##set up output variables\n",
    "        self.Wo = theano.shared(init_weight(self.H,self.V))\n",
    "        self.bo = theano.shared(np.zeros(self.V))\n",
    "        \n",
    "        #will set all lstm variable in instance variable params\n",
    "        #will also set dparams variable\n",
    "        self.params = [self.We,self.C0,self.h0,self.Wfx,self.Wfh,self.bfh,self.Wix,self.Wih,self.bih,\n",
    "                      self.WCx,self.WCh,self.bCh,self.Wox,self.Woh,self.boh,self.Wo,self.bo]\n",
    "        #delta of the params\n",
    "        self.dparams = [theano.shared(param.get_value()*0) for param in self.params]\n",
    "        \n",
    "        def recurrance(x_t,h_t1,C_t1):\n",
    "            ft = T.nnet.sigmoid(x_t.dot(self.Wfx)+ h_t1.dot(self.Wfh) + self.bfh)\n",
    "            it = T.nnet.sigmoid(x_t.dot(self.Wix)+ h_t1.dot(self.Wih) + self.bih)\n",
    "            Cdasht = T.tanh(x_t.dot(self.WCx)+ h_t1.dot(self.WCh) + self.bCh)\n",
    "            ot = T.nnet.sigmoid(x_t.dot(self.Wox)+ h_t1.dot(self.Woh) + self.boh)\n",
    "            C_t = ft*C_t1 + it*Cdasht\n",
    "            ot = T.nnet.sigmoid(x_t.dot(self.Wox)+ h_t1.dot(self.Woh) + self.boh)\n",
    "            h_t = ot*T.tanh(C_t)\n",
    "            return h_t,C_t\n",
    "        \n",
    "        #forward run of sequence\n",
    "        [h,C],_ = theano.scan(\n",
    "                                fn = recurrance,\n",
    "                                sequences=Ei,\n",
    "                                outputs_info=[self.h0,self.C0],\n",
    "                                n_steps=Ei.shape[0]\n",
    "                            )\n",
    "        \n",
    "        py_x = T.nnet.softmax(h.dot(self.Wo) + self.bo)\n",
    "        \n",
    "        prediction = T.argmax(py_x,axis=1)\n",
    "        \n",
    "        cost = -1*T.mean(T.log(py_x[T.arange(thY.shape[0]),thY]))\n",
    "        grads = T.grad(cost,self.params)\n",
    "        \n",
    "        \n",
    "        updates = [(p,p + (mu*dp - alpha*g)) for g,p,dp in zip(grads,self.params,self.dparams)] + [\n",
    "            (dp,mu*dp - alpha*g) for g,p,dp in zip(grads,self.params,self.dparams)\n",
    "        ]\n",
    "        self.train = theano.function(\n",
    "            inputs = [thX,thY],\n",
    "            outputs = [cost,prediction],\n",
    "            updates = updates\n",
    "        )\n",
    "        \n",
    "        self.predict = theano.function(\n",
    "            inputs = [thX],\n",
    "            outputs = [prediction]\n",
    "        )\n",
    "        \n",
    "        count = 0\n",
    "        costs = []\n",
    "        n_total = sum([len(row) for row in X])\n",
    "        for e in xrange(epochs):\n",
    "            first = True\n",
    "            cost = 0\n",
    "            total_correct_words = 0\n",
    "            X = shuffle(X)\n",
    "            for row in X:\n",
    "                trainX = [0] + row\n",
    "                trainY = row + [1]\n",
    "                [c,prediction] = self.train(thX=trainX,thY=trainY)\n",
    "                for p,t in zip(prediction,trainY):\n",
    "                    if p==t:\n",
    "                        total_correct_words = total_correct_words + 1\n",
    "                count = count + 1\n",
    "                cost = cost + c\n",
    "            print \"Cost is\",cost,\" Prediction is\",(1.0*total_correct_words)/n_total\n",
    "            costs.append(cost)\n",
    "        plt.plot(costs)\n",
    "    def generate(self,word2idx,num_lines,sentences):\n",
    "        \n",
    "            current = 0\n",
    "\n",
    "            #creating the inverted index map\n",
    "            idx2word = {}\n",
    "            for key,value in word2idx.iteritems():\n",
    "                idx2word[value]=key\n",
    "\n",
    "            #start_words = np.random.choice(len(sentences),num_lines)\n",
    "            X = [sentences[np.random.choice(len(sentences))][0]]\n",
    "            while current<num_lines:\n",
    "                #print X\n",
    "                [pred] = self.predict(thX=X)\n",
    "                #print pred\n",
    "                next_word = pred[-1]\n",
    "                if idx2word[next_word]=='END':\n",
    "                    current = current + 1\n",
    "                    #print \"\\n\"\n",
    "                    sentence = \" \"\n",
    "                    for num in X:\n",
    "                        sentence += \" \" + idx2word[num] \n",
    "                    print sentence\n",
    "                    X = [sentences[np.random.choice(len(sentences))][0]]                \n",
    "                    #if current<num_lines:\n",
    "                    #    print idx2word[X[0]]\n",
    "                else:\n",
    "                    #print idx2word[next_word]\n",
    "                    X.append(next_word)\n",
    "    def save(self,filename):\n",
    "            np.savez(filename, *[param.get_value() for param in self.params])\n",
    "            npz = np.load(filename)\n",
    "            print npz['arr_0']\n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "            if not os.path.exists(filename):\n",
    "                raise Excpetion(\"File\"+path+\"does not exist\")\n",
    "            params = [\"We\",\"C0\",\"h0\",\"Wfx\",\"Wfh\",\"bfh\",\"Wix\",\"Wih\",\"bih\",\n",
    "                      \"WCx\",\"WCh\",\"bCh\",\"Wox\",\"Woh\",\"boh\",\"Wo\",\"bo\"]\n",
    "            count = 0\n",
    "            npz = np.load(filename)\n",
    "            We = npz['arr_0']\n",
    "            C0 = npz['arr_1']\n",
    "            M = C0.shape[0]\n",
    "            D,V = We.shape\n",
    "            \n",
    "            ls = lstm(M,D,V)\n",
    "            \n",
    "            for p in params:\n",
    "                setattr(ls,p,theano.shared(npz[\"arr_\"+`count`]))\n",
    "                count += 1\n",
    "            ls.set_variables()\n",
    "            return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls = lstm(30,30,len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost is 11019.9409834  Prediction is 0.132512131392\n",
      "Cost is 10603.9525709  Prediction is 0.134005225831\n",
      "Cost is 10217.7603248  Prediction is 0.134005225831\n",
      "Cost is 9962.96698169  Prediction is 0.134005225831\n",
      "Cost is 9791.45621623  Prediction is 0.134005225831\n",
      "Cost is 9589.93050361  Prediction is 0.134005225831\n",
      "Cost is 9394.50426392  Prediction is 0.134005225831\n",
      "Cost is 9233.90379919  Prediction is 0.134005225831\n",
      "Cost is 9108.08656161  Prediction is 0.134005225831\n",
      "Cost is 9005.27826983  Prediction is 0.134005225831\n",
      "Cost is 8926.76153202  Prediction is 0.134005225831\n",
      "Cost is 8866.32549539  Prediction is 0.134005225831\n",
      "Cost is 8814.31202894  Prediction is 0.134005225831\n",
      "Cost is 8762.95108485  Prediction is 0.134191862635\n",
      "Cost is 8709.99035728  Prediction is 0.143243747667\n",
      "Cost is 8669.30775309  Prediction is 0.15313549832\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "alloc failed\nApply node that caused the error: Alloc(TensorConstant{(1L, 1L) of 0.0}, Shape_i{0}.0, Shape_i{1}.0)\nToposort index: 70\nInputs types: [TensorType(float64, (True, True)), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(1L, 1L), (), ()]\nInputs strides: [(8L, 8L), (), ()]\nInputs values: [array([[ 0.]]), array(2446L, dtype=int64), array(30L, dtype=int64)]\nOutputs clients: [[AdvancedIncSubtensor1{inplace,inc}(Alloc.0, IncSubtensor{InplaceInc;int64::}.0, thX)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-110-38aa85225b89>\", line 1, in <module>\n    ls.fit(sentences,epochs=20)\n  File \"<ipython-input-101-4bac53c87543>\", line 113, in fit\n    grads = T.grad(cost,self.params)\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 555, in grad\n    grad_dict, wrt, cost_name)\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1317, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1272, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1108, in access_term_cache\n    new_output_grads)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-38aa85225b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lstm_30_30_20.npz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-4bac53c87543>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, alpha, mu, print_period, epochs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mtrainX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: alloc failed\nApply node that caused the error: Alloc(TensorConstant{(1L, 1L) of 0.0}, Shape_i{0}.0, Shape_i{1}.0)\nToposort index: 70\nInputs types: [TensorType(float64, (True, True)), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(1L, 1L), (), ()]\nInputs strides: [(8L, 8L), (), ()]\nInputs values: [array([[ 0.]]), array(2446L, dtype=int64), array(30L, dtype=int64)]\nOutputs clients: [[AdvancedIncSubtensor1{inplace,inc}(Alloc.0, IncSubtensor{InplaceInc;int64::}.0, thX)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-110-38aa85225b89>\", line 1, in <module>\n    ls.fit(sentences,epochs=20)\n  File \"<ipython-input-101-4bac53c87543>\", line 113, in fit\n    grads = T.grad(cost,self.params)\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 555, in grad\n    grad_dict, wrt, cost_name)\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1317, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1272, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"C:\\Users\\parmeets\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\theano\\gradient.py\", line 1108, in access_term_cache\n    new_output_grads)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "ls.fit(sentences,epochs=20)\n",
    "ls.save(\"lstm_30_30_20.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I\n",
      "  How\n",
      "  The\n",
      "  Walls\n",
      "  So\n",
      "  Dont\n",
      "  Was\n",
      "  With\n",
      "  The\n",
      "  To\n"
     ]
    }
   ],
   "source": [
    "ls.generate(vocabulary,10,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  On\n",
      "  But\n",
      "  They\n",
      "  And\n",
      "  Except\n",
      "  Havent\n",
      "  And\n",
      "  And\n",
      "  Our\n",
      "  Two\n"
     ]
    }
   ],
   "source": [
    "ls2 = lstm.load(\"lstm_30_30_20.npz\")\n",
    "ls2.generate(vocabulary,10,sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls2 = lstm.load(\"lstm_30_30.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I\n",
      "  Like\n",
      "  You\n",
      "  Legitimately\n",
      "  Its\n",
      "  Moving\n",
      "  There\n",
      "  From\n",
      "  I\n",
      "  My\n"
     ]
    }
   ],
   "source": [
    "ls2.generate(vocabulary,10,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npfile = np.load(\"save.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

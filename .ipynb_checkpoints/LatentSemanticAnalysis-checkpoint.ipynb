{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_reviews = bs(open('datasets/sentiment/positive.review').read())\n",
    "positive_reviews = positive_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "negative_reviews = bs(open('datasets/sentiment/negative.review').read())\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(positive_reviews)\n",
    "sizeNr = len(negative_reviews)\n",
    "positive_reviews = positive_reviews[0:sizeNr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordnetlemmatizer = WordNetLemmatizer()\n",
    "stopwords = [word.strip() for word in open('datasets/stopwords.txt')]\n",
    "def CustomTokenizer(review):\n",
    "    #make all reviews lower cased\n",
    "    review = review.lower()\n",
    "    #tokenize all words\n",
    "    review = nltk.tokenize.word_tokenize(review)\n",
    "    #removing all stop words\n",
    "    review = [word for word in review if word not in stopwords]\n",
    "    #removing all words with less than two characters\n",
    "    review = [word for word in review if len(word)>2]\n",
    "    #lemmatizing the word\n",
    "    review = [wordnetlemmatizer.lemmatize(word) for word in review]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dictionary indicating words to index\n",
    "word2idx = {}\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "current = 0\n",
    "for review in positive_reviews:\n",
    "    review = CustomTokenizer(review.text)\n",
    "    review.append(1)\n",
    "    positive_tokenized.append(review)\n",
    "    for token in review:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = current\n",
    "            current += 1\n",
    "for review in negative_reviews:\n",
    "    review = CustomTokenizer(review.text)\n",
    "    review.append(0)\n",
    "    negative_tokenized.append(review)\n",
    "    for token in review:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = current\n",
    "            current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#size of the dataset\n",
    "D = len(negative_tokenized) + len(positive_tokenized)\n",
    "#size of the vocabulary, 1 added for the label\n",
    "V = len(word2idx)\n",
    "#document-term matrix\n",
    "dt = np.zeros((D,V))\n",
    "y = np.zeros(D)\n",
    "combined_reviews = negative_tokenized + positive_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#populating the document-term matrix\n",
    "document_num = 0\n",
    "for review in positive_tokenized:\n",
    "    for token in review:\n",
    "        dt[document_num][word2idx[token]] += 1\n",
    "    dt[document_num] /= sum(dt[document_num])\n",
    "    y[document_num] = 1\n",
    "    document_num +=  1    \n",
    "#populating the document-term matrix\n",
    "for review in negative_tokenized:\n",
    "    for token in review:\n",
    "        dt[document_num][word2idx[token]] += 1\n",
    "    dt[document_num] /= sum(dt[document_num])    \n",
    "    y[document_num] = 0\n",
    "    document_num +=  1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dt,y,test_size=0.20)\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9503105590062112"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9691358 ,  0.99382716,  0.99375   ,  0.98125   ,  0.9875    ])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lg,dt,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
